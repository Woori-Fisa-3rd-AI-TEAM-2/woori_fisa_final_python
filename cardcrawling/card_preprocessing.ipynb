{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "credit = pd.read_csv('creditcard_raw.csv')\n",
    "check = pd.read_csv('checkcard_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace values in a column based on keywords\n",
    "def replace_with_extracted_sentences(row, column, keyword_list):\n",
    "    if pd.notnull(row[column]) and any(kw in row[column] for kw in keyword_list):\n",
    "        sentences = [\n",
    "            (row[column].replace('\\n', ' ').split('.')[i-1] + \" \" + sentence if i > 0 else sentence)\n",
    "            for i, sentence in enumerate(row[column].replace('\\n', ' ').split('.'))\n",
    "            if any(kw in sentence for kw in keyword_list)\n",
    "        ]\n",
    "        return ' '.join(sentences)  # Join sentences back into a single string\n",
    "    return np.nan  # Return NaN if no keywords found\n",
    "\n",
    "def extract_first_two_sentences(value):\n",
    "    if pd.notnull(value):\n",
    "        sentences = value.split('\\n')\n",
    "        return ' '.join(sentences[:2]).replace('\\n', ' ')\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "keywords = {\n",
    "    'convenience': ['편의점 업종', 'CU', 'GS25', '세븐일레븐', '이마트24', '미니스톱'],\n",
    "    'cafe': ['스타벅스', '커피빈', '투썸', '카페베네', '이디야'],\n",
    "    'oil': ['GS칼텍스', 'SK에너지', 'S-OIL', '에이치디현대오일뱅크'],\n",
    "    'movie': ['CGV', '롯데시네마', '전국 영화관', '메가박스'],\n",
    "    'mart': ['이마트', '롯데마트', '홈플러스', '대형마트']\n",
    "}\n",
    "\n",
    "\n",
    "columns_to_process = ['restaurant', 'shopping', 'hospital', 'edu', 'tel', 'car', 'travel', 'transportation']\n",
    "\n",
    "\n",
    "for column, keyword_list in keywords.items():\n",
    "    if column in credit.columns:  # Check if the column exists in the DataFrame\n",
    "        credit[column] = credit.apply(lambda row: replace_with_extracted_sentences(row, column, keyword_list), axis=1)\n",
    "\n",
    "\n",
    "for column in columns_to_process:\n",
    "    if column in credit.columns:\n",
    "        credit[column] = credit[column].apply(extract_first_two_sentences)\n",
    "\n",
    "\n",
    "#모두 nan인 값 제거\n",
    "columns = [col for col in ['convenience', 'cafe', 'restaurant', 'oil', 'movie', 'mart', \n",
    "                                    'shopping', 'hospital', 'edu', 'tel', 'car', 'travel', 'transportation'] \n",
    "                    if col in credit.columns]\n",
    "\n",
    "# 존재하는 컬럼들이 모두 NaN인 행을 제거\n",
    "credit = credit.dropna(subset=columns, how='all')\n",
    "credit.reset_index(inplace= True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace values in a column based on keywords\n",
    "def replace_with_extracted_sentences(row, column, keyword_list):\n",
    "    if pd.notnull(row[column]) and any(kw in row[column] for kw in keyword_list):\n",
    "        sentences = [\n",
    "            (row[column].replace('\\n', ' ').split('.')[i-1] + \" \" + sentence if i > 0 else sentence)\n",
    "            for i, sentence in enumerate(row[column].replace('\\n', ' ').split('.'))\n",
    "            if any(kw in sentence for kw in keyword_list)\n",
    "        ]\n",
    "        return ' '.join(sentences)  # Join sentences back into a single string\n",
    "    return np.nan  # Return NaN if no keywords found\n",
    "\n",
    "def extract_first_two_sentences(value):\n",
    "    if pd.notnull(value):\n",
    "        sentences = value.split('\\n')\n",
    "        return ' '.join(sentences[:2]).replace('\\n', ' ')\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "keywords = {\n",
    "    'convenience': ['편의점 업종', 'CU', 'GS25', '세븐일레븐', '이마트24', '미니스톱'],\n",
    "    'cafe': ['스타벅스', '커피빈', '투썸', '카페베네', '이디야'],\n",
    "    'oil': ['GS칼텍스', 'SK에너지', 'S-OIL', '에이치디현대오일뱅크'],\n",
    "    'movie': ['CGV', '롯데시네마', '전국 영화관', '메가박스'],\n",
    "    'mart': ['이마트', '롯데마트', '홈플러스', '대형마트']\n",
    "}\n",
    "\n",
    "\n",
    "columns_to_process = ['restaurant', 'shopping', 'hospital', 'edu', 'tel', 'car', 'travel', 'transportation']\n",
    "\n",
    "\n",
    "for column, keyword_list in keywords.items():\n",
    "    if column in check.columns:  # Check if the column exists in the DataFrame\n",
    "        check[column] = check.apply(lambda row: replace_with_extracted_sentences(row, column, keyword_list), axis=1)\n",
    "\n",
    "\n",
    "for column in columns_to_process:\n",
    "    if column in check.columns:\n",
    "        check[column] = check[column].apply(extract_first_two_sentences)\n",
    "\n",
    "\n",
    "#모두 nan인 값 제거\n",
    "columns = [col for col in ['convenience', 'cafe', 'restaurant', 'oil', 'movie', 'mart', \n",
    "                                    'shopping', 'hospital', 'edu', 'tel', 'car', 'travel', 'transportation'] \n",
    "                    if col in check.columns]\n",
    "\n",
    "# 존재하는 컬럼들이 모두 NaN인 행을 제거\n",
    "check = check.dropna(subset=columns, how='all')\n",
    "check.reset_index(inplace= True, drop=True)\n",
    "check = check.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.to_csv('creditcard.csv')\n",
    "check.to_csv('checkcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'brand', 'img_url', 'card_url', 'convenience', 'cafe',\n",
       "       'restaurant', 'oil', 'movie', 'mart', 'shopping', 'hospital', 'edu',\n",
       "       'tel', 'car', 'travel', 'transportation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'brand', 'img_url', 'card_url', 'convenience', 'cafe',\n",
       "       'restaurant', 'oil', 'movie', 'mart', 'shopping', 'hospital', 'edu',\n",
       "       'tel', 'car', 'travel', 'transportation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
